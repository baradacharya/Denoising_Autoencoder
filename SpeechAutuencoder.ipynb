{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "# Few import statements\n",
    "import os\n",
    "import scipy.io.wavfile as wav\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import load_model, save_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import TimeDistributedDense\n",
    "from keras.layers.recurrent import LSTM\n",
    "from IPython.display import Audio\n",
    "from pipes import quote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_wav_as_np(file):\n",
    "    # wav.read returns the sampling rate per second  (as an int) and the data (as a numpy array)\n",
    "    data = wav.read(file)    \n",
    "    # Normalize 16-bit input to [-1, 1] range\n",
    "    np_arr = data[1].astype('float32') / 32767.0\n",
    "    #np_arr = np.array(np_arr)\n",
    "    return np_arr, data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_np_as_wav(X, sample_rate, file):\n",
    "    # Converting the tensor back to it's original form\n",
    "    Xnew = X * 32767.0\n",
    "    Xnew = Xnew.astype('int16')\n",
    "    # wav.write constructs the .wav file using the specified sample_rate and tensor\n",
    "    wav.write(file, sample_rate, Xnew)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_sample_blocks_to_np_audio(blocks):\n",
    "    # Flattens the blocks into a single list\n",
    "    song_np = np.concatenate(blocks)\n",
    "    return song_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_np_audio_to_sample_blocks(song_np, block_size):\n",
    "\n",
    "    # Block lists initialised\n",
    "    block_lists = []\n",
    "\n",
    "    # total_samples holds the size of the numpy array\n",
    "    total_samples = song_np.shape[0]\n",
    "    # print('total_samples=',total_samples)\n",
    "\n",
    "    # num_samples_so_far is used to loop through the numpy array\n",
    "    num_samples_so_far = 0\n",
    "\n",
    "    while (num_samples_so_far < total_samples):\n",
    "\n",
    "        # Stores each block in the \"block\" variable\n",
    "        block = song_np[num_samples_so_far:num_samples_so_far + block_size]\n",
    "\n",
    "        if (block.shape[0] < block_size):\n",
    "            # this is to add 0's in the last block if it not completely filled\n",
    "            padding = np.zeros((block_size - block.shape[0],))\n",
    "            # block_size is 4400 which is fixed throughout whereas block.shape[0] for the last block is <=44100\n",
    "            block = np.concatenate((block,padding))\n",
    "        block_lists.append(block)\n",
    "        num_samples_so_far += block_size\n",
    "    return block_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def time_blocks_to_fft_blocks(blocks_time_domain):\n",
    "    # FFT blocks initialized\n",
    "    fft_blocks = []\n",
    "    for block in blocks_time_domain:\n",
    "        # Computes the one-dimensional discrete Fourier Transform and returns the complex nD array\n",
    "        # i.e The truncated or zero-padded input, transformed from time domain to frequency domain.\n",
    "        fft_block = np.fft.fft(block)\n",
    "        # Joins a sequence of blocks along frequency axis.\n",
    "        new_block = np.concatenate((np.real(fft_block), np.imag(fft_block)))\n",
    "        fft_blocks.append(new_block)\n",
    "    return fft_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fft_blocks_to_time_blocks(blocks_ft_domain):\n",
    "    # Time blocks initialized\n",
    "    time_blocks = []\n",
    "    for block in blocks_ft_domain:\n",
    "        num_elems = block.shape[0] / 2\n",
    "        # Extracts real part of the amplitude corresponding to the frequency\n",
    "        real_chunk = block[0:num_elems]\n",
    "        # Extracts imaginary part of the amplitude corresponding to the frequency\n",
    "        imag_chunk = block[num_elems:]\n",
    "        # Represents amplitude as a complex number corresponding to the frequency\n",
    "        new_block = real_chunk + 1.0j * imag_chunk\n",
    "        # Computes the one-dimensional discrete inverse Fourier Transform and returns the transformed\n",
    "        # block from frequency domain to time domain\n",
    "        time_block = np.fft.ifft(new_block)\n",
    "        # Joins a sequence of blocks along time axis.\n",
    "        time_blocks.append(time_block)\n",
    "    return time_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_frequency = 44100\n",
    "block_size = 4400\n",
    "filename = 'F01_22GC010A_BTH.CH0.wav'\n",
    "filename_noisy = \"F01_22GC010A_BUS.CH0.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 79200\n",
      "17 74800\n"
     ]
    }
   ],
   "source": [
    "# wav_array contains normalized data\n",
    "wav_clean, bitrate = read_wav_as_np(filename)\n",
    "# wav_array is converted into blocks with zeroes padded to fill the empty space in last block if any\n",
    "wav_blocks_zero_padded_clean = convert_np_audio_to_sample_blocks(wav_clean, block_size)\n",
    "wav_array_clean = convert_sample_blocks_to_np_audio(wav_blocks_zero_padded_clean)\n",
    "print len(wav_blocks_zero_padded_clean), len(wav_array_clean)\n",
    "wav_noisy, bitrate = read_wav_as_np(filename_noisy)\n",
    "wav_blocks_zero_padded_noisy = convert_np_audio_to_sample_blocks(wav_noisy, block_size)\n",
    "wav_array_noisy = convert_sample_blocks_to_np_audio(wav_blocks_zero_padded_noisy)\n",
    "print len(wav_blocks_zero_padded_noisy), len(wav_array_noisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def making_same_length(clean, noisy):    \n",
    "    if(len(clean) > len(noisy)):\n",
    "        pad = len(clean) - len(noisy)\n",
    "        for i in range(pad):\n",
    "            noisy.append(np.zeros(block_size))\n",
    "        return clean, noisy\n",
    "    else:\n",
    "        pad = len(noisy) - len(clean)\n",
    "        \n",
    "        for i in range(pad):\n",
    "            clean.append(np.zeros(block_size))\n",
    "        return clean, noisy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 18\n"
     ]
    }
   ],
   "source": [
    "making_same_length(wav_blocks_zero_padded_clean, wav_blocks_zero_padded_noisy)\n",
    "print len(wav_blocks_zero_padded_clean), len(wav_blocks_zero_padded_noisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "print len(wav_blocks_zero_padded_noisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Dimension of wav blocks before fft: ', (18L, 4400L))\n",
      "('Dimension of the training dataset (wav blocks after fft): ', (18L, 8800L))\n"
     ]
    }
   ],
   "source": [
    "# Fast fourier transforming the wav blocks into frequency domain\n",
    "print('Dimension of wav blocks before fft: ',np.shape(wav_blocks_zero_padded_clean))\n",
    "\n",
    "Y = time_blocks_to_fft_blocks(wav_blocks_zero_padded_clean)\n",
    "X = time_blocks_to_fft_blocks(wav_blocks_zero_padded_noisy)\n",
    "\n",
    "print('Dimension of the training dataset (wav blocks after fft): ',np.shape(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(78333L,)\n",
      "(18L, 8800L)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-c977f928f7be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mseed_seq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mval_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mit\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mseed_seq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed_seq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed_seq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed_seq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mseedSeqNew\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed_seq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseedSeqNew\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseedSeqNew\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "f1 = \"F01_22GC010A_BTH.CH0.wav\"\n",
    "wav_test, bitrate = read_wav_as_np(f1)\n",
    "print np.shape(wav_test)\n",
    "test = convert_np_audio_to_sample_blocks(wav_test, block_size)\n",
    "test = time_blocks_to_fft_blocks(test)\n",
    "print np.shape(test)\n",
    "cur_seq = 0\n",
    "chunks_val = []\n",
    "max_seq_len = 1\n",
    "total_seq = len(test)\n",
    "while cur_seq + max_seq_len <= total_seq:\n",
    "    chunks_val.append(test[cur_seq:cur_seq + max_seq_len])    \n",
    "    cur_seq += max_seq_len\n",
    "# Number of examples\n",
    "num_examples = len(chunks_val) \n",
    "# Imaginary part requires the extra space\n",
    "num_dims_out = block_size * 2\n",
    "# Dimensions of the training dataset\n",
    "out_shape = (num_examples, max_seq_len, num_dims_out)\n",
    "val_data = np.zeros(out_shape)\n",
    "# Populating the training dataset\n",
    "for n in range(num_examples):\n",
    "    for i in range(max_seq_len):\n",
    "        val_data[n][i] = chunks_val[n][i]    \n",
    "        \n",
    "output = []\n",
    "for it in range(val_data.shape[0]):\n",
    "    seed_seq = val_data[it]\n",
    "    seed_seq = np.reshape(seed_seq, (1, seed_seq.shape[0], seed_seq.shape[1]))\n",
    "    seedSeqNew = model.predict(seed_seq)    \n",
    "    for i in range(seedSeqNew.shape[1]):\n",
    "        output.append(seedSeqNew[0][i].copy())\n",
    "\n",
    "print np.shape(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur_seq = 0\n",
    "chunks_X = []\n",
    "chunks_Y = []\n",
    "max_seq_len = 1\n",
    "total_seq = len(X)\n",
    "while cur_seq + max_seq_len <= total_seq:\n",
    "    chunks_X.append(X[cur_seq:cur_seq + max_seq_len])\n",
    "    chunks_Y.append(Y[cur_seq:cur_seq + max_seq_len])\n",
    "    cur_seq += max_seq_len\n",
    "# Number of examples\n",
    "num_examples = len(chunks_X) \n",
    "# Imaginary part requires the extra space\n",
    "num_dims_out = block_size * 2\n",
    "# Dimensions of the training dataset\n",
    "out_shape = (num_examples, max_seq_len, num_dims_out)\n",
    "x_data = np.zeros(out_shape)\n",
    "y_data = np.zeros(out_shape)\n",
    "# Populating the training dataset\n",
    "for n in range(num_examples):\n",
    "    for i in range(max_seq_len):\n",
    "        x_data[n][i] = chunks_X[n][i]\n",
    "        y_data[n][i] = chunks_Y[n][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18L, 1L, 8800L)\n"
     ]
    }
   ],
   "source": [
    "print np.shape(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18L, 1L, 8800L) (18L, 1L, 8800L)\n"
     ]
    }
   ],
   "source": [
    "print np.shape(x_data), np.shape(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Input layer size: ', 8800)\n",
      "('Hidden layer size: ', 1024)\n",
      "('length: ', 1L)\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "timedistributeddense_3 (TimeDist (None, 1L, 1024)      9012224     timedistributeddense_input_2[0][0\n",
      "____________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                    (None, 1L, 1024)      8392704     timedistributeddense_3[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "lstm_5 (LSTM)                    (None, 1L, 1024)      8392704     lstm_4[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "lstm_6 (LSTM)                    (None, 1L, 1024)      8392704     lstm_5[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "timedistributeddense_4 (TimeDist (None, 1L, 8800)      9020000     lstm_6[0][0]                     \n",
      "====================================================================================================\n",
      "Total params: 43,210,336\n",
      "Trainable params: 43,210,336\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_frequency_dimensions = 8800\n",
    "num_hidden_dimensions = 1024\n",
    "length = np.shape(x_data)[1]\n",
    "print('Input layer size: ',num_frequency_dimensions)\n",
    "print('Hidden layer size: ',num_hidden_dimensions)\n",
    "print(\"length: \", length)\n",
    "# Sequential is a linear stack of layers\n",
    "model = Sequential()\n",
    "# This layer converts frequency space to hidden space\n",
    "model.add(TimeDistributedDense(input_dim=num_frequency_dimensions, output_dim=num_hidden_dimensions, input_length=length))\n",
    "# return_sequences=True implies return the entire output sequence & not just the last output\n",
    "model.add(LSTM(input_dim=num_hidden_dimensions, output_dim=num_hidden_dimensions, return_sequences=True))\n",
    "#add LSTM\n",
    "model.add(LSTM(input_dim=num_hidden_dimensions, output_dim=num_hidden_dimensions, return_sequences=True))\n",
    "model.add(LSTM(input_dim=num_hidden_dimensions, output_dim=num_hidden_dimensions, return_sequences=True))\n",
    "# This layer converts hidden space back to frequency space\n",
    "model.add(TimeDistributedDense(input_dim=num_hidden_dimensions, output_dim=num_frequency_dimensions))\n",
    "# Done building the model.Now, configure it for the learning process\n",
    "model.compile(loss='mean_squared_error', optimizer='rmsprop')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_model(model, x_data, y_data):\n",
    "    # Number of iterations for training\n",
    "    num_iters = 10\n",
    "    # Number of iterations before we save our model\n",
    "    epochs_per_iter = 3\n",
    "    # Number of training examples pushed to the GPU per batch.\n",
    "    batch_size = 256\n",
    "    # Path to weights file    \n",
    "    cur_iter = 0\n",
    "    while cur_iter < num_iters:\n",
    "        print('Iteration: ' + str(cur_iter))\n",
    "        # Iterate over the training data in batches\n",
    "        history = model.fit(x_data, y_data, batch_size=batch_size, nb_epoch=epochs_per_iter, verbose=1, validation_split=0.0)\n",
    "        cur_iter += epochs_per_iter\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "timedistributeddense_3 (TimeDist (None, 1L, 1024)      9012224     timedistributeddense_input_2[0][0\n",
      "____________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                    (None, 1L, 1024)      8392704     timedistributeddense_3[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "lstm_5 (LSTM)                    (None, 1L, 1024)      8392704     lstm_4[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "lstm_6 (LSTM)                    (None, 1L, 1024)      8392704     lstm_5[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "timedistributeddense_4 (TimeDist (None, 1L, 8800)      9020000     lstm_6[0][0]                     \n",
      "====================================================================================================\n",
      "Total params: 43,210,336\n",
      "Trainable params: 43,210,336\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "Iteration: 0\n",
      "Epoch 1/3\n",
      "8805/8805 [==============================] - 120s - loss: 3.8826   \n",
      "Epoch 2/3\n",
      "8805/8805 [==============================] - 111s - loss: 3.8319   \n",
      "Epoch 3/3\n",
      "8805/8805 [==============================] - 109s - loss: 3.7794   \n",
      "Iteration: 3\n",
      "Epoch 1/3\n",
      "8805/8805 [==============================] - 115s - loss: 3.7342   \n",
      "Epoch 2/3\n",
      "8805/8805 [==============================] - 120s - loss: 3.6811   \n",
      "Epoch 3/3\n",
      "8805/8805 [==============================] - 109s - loss: 3.6297   \n",
      "Iteration: 6\n",
      "Epoch 1/3\n",
      "8805/8805 [==============================] - 123s - loss: 3.5821   \n",
      "Epoch 2/3\n",
      "8805/8805 [==============================] - 122s - loss: 3.5334   \n",
      "Epoch 3/3\n",
      "8805/8805 [==============================] - 126s - loss: 3.4814   \n",
      "Iteration: 9\n",
      "Epoch 1/3\n",
      "8805/8805 [==============================] - 122s - loss: 3.4328   \n",
      "Epoch 2/3\n",
      "8805/8805 [==============================] - 119s - loss: 3.3875   \n",
      "Epoch 3/3\n",
      "8805/8805 [==============================] - 120s - loss: 3.3366   \n"
     ]
    }
   ],
   "source": [
    "model_name = \"model_1\"\n",
    "#model = load_model(\"weights/model_1.hdf5\")\n",
    "print model.summary()\n",
    "num_iters = 10\n",
    "# Number of iterations before we save our model\n",
    "epochs_per_iter = 3\n",
    "# Number of training examples pushed to the GPU per batch.\n",
    "batch_size = 64\n",
    "# Path to weights file    \n",
    "cur_iter = 0\n",
    "while cur_iter < num_iters:\n",
    "    print('Iteration: ' + str(cur_iter))\n",
    "    # Iterate over the training data in batches\n",
    "    history = model.fit(X, Y, batch_size=batch_size, nb_epoch=epochs_per_iter, verbose=1, validation_split=0.0)\n",
    "    cur_iter += epochs_per_iter\n",
    "\n",
    "model.save('weights/%s.hdf5'%model_name, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F01_053C0105_BUS.CH0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rajesh\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:4: ComplexWarning: Casting complex values to real discards the imaginary part\n"
     ]
    }
   ],
   "source": [
    "y, x = data_train[10]\n",
    "print x\n",
    "x_block = read_file_as_blocks(x, \"noisy\")\n",
    "x_data = convert_block_to_data(x_block)\n",
    "predict_and_dump_output(model, x_data, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rajesh\\Anaconda2\\lib\\site-packages\\keras\\layers\\core.py:1205: UserWarning: `TimeDistributedDense` is deprecated, And will be removed on May 1st, 2017. Please use a `Dense` layer instead.\n",
      "  warnings.warn('`TimeDistributedDense` is deprecated, '\n"
     ]
    }
   ],
   "source": [
    "# model = load_model(\"weights/model.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output = []\n",
    "for it in range(x_data.shape[0]):\n",
    "    seed_seq = x_data[it]\n",
    "    seed_seq = np.reshape(seed_seq, (1, seed_seq.shape[0], seed_seq.shape[1]))\n",
    "    seedSeqNew = model.predict(seed_seq)    \n",
    "    for i in range(seedSeqNew.shape[1]):\n",
    "        output.append(seedSeqNew[0][i].copy())\n",
    "    \n",
    "            \n",
    "    #output.append(seedSeqNew[])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "print len(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rajesh\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:4: ComplexWarning: Casting complex values to real discards the imaginary part\n"
     ]
    }
   ],
   "source": [
    "# The path for the generated song\n",
    "song_path = 'clean_2.wav'\n",
    "# Reversing the conversions\n",
    "time_blocks = fft_blocks_to_time_blocks(output)\n",
    "song = convert_sample_blocks_to_np_audio(time_blocks)\n",
    "write_np_as_wav(song, 15000, song_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_file_as_blocks(filename, folder):\n",
    "    block_size = 4400\n",
    "    filename = \"files/\" + folder + \"/\" + filename    \n",
    "    wav_test, bitrate = read_wav_as_np(filename)\n",
    "    test = convert_np_audio_to_sample_blocks(wav_test, block_size)    \n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#converting wav file to data\n",
    "def convert_block_to_data(test):        \n",
    "    test = time_blocks_to_fft_blocks(test)\n",
    "    #print np.shape(test)\n",
    "    cur_seq = 0\n",
    "    chunks_val = []\n",
    "    max_seq_len = 1\n",
    "    total_seq = len(test)\n",
    "    while cur_seq + max_seq_len <= total_seq:\n",
    "        chunks_val.append(test[cur_seq:cur_seq + max_seq_len])    \n",
    "        cur_seq += max_seq_len\n",
    "    # Number of examples\n",
    "    num_examples = len(chunks_val) \n",
    "    # Imaginary part requires the extra space\n",
    "    num_dims_out = block_size * 2\n",
    "    # Dimensions of the training dataset\n",
    "    out_shape = (num_examples, max_seq_len, num_dims_out)\n",
    "    data = np.zeros(out_shape)\n",
    "    # Populating the training dataset\n",
    "    for n in range(num_examples):\n",
    "        for i in range(max_seq_len):\n",
    "            data[n][i] = chunks_val[n][i]\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_and_dump_output(model, data, filename):    \n",
    "    output = []\n",
    "    for it in range(data.shape[0]):\n",
    "        seed_seq = data[it]\n",
    "        seed_seq = np.reshape(seed_seq, (1, seed_seq.shape[0], seed_seq.shape[1]))\n",
    "        seedSeqNew = model.predict(seed_seq)    \n",
    "        for i in range(seedSeqNew.shape[1]):\n",
    "            output.append(seedSeqNew[0][i].copy())\n",
    "    \n",
    "    song_path = 'files/predict/'+ filename.split('.')[0] + '_predicted.wav'\n",
    "    # Reversing the conversions\n",
    "    time_blocks = fft_blocks_to_time_blocks(output)\n",
    "    song = convert_sample_blocks_to_np_audio(time_blocks)\n",
    "    write_np_as_wav(song, 15000, song_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "clean_names = []\n",
    "noisy_names = []\n",
    "walk_dir = \"files/clean\"\n",
    "\n",
    "for root, subdirs, files in os.walk(walk_dir):\n",
    "    for f in files:\n",
    "        if(f.endswith(\".CH0.wav\")): \n",
    "            clean_names.append(f)\n",
    "\n",
    "walk_dir = \"files/noisy\"\n",
    "for root, subdirs, files in os.walk(walk_dir):\n",
    "    for f in files:        \n",
    "        if(f.endswith(\".CH0.wav\")):            \n",
    "            noisy_names.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "410\n"
     ]
    }
   ],
   "source": [
    "print len(noisy_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rajesh\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "files = zip(clean_names, noisy_names)\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "data_train, data_test = train_test_split(files, test_size=0.10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('M03_22GC0105_BTH.CH0.wav', 'M03_22GC0105_BUS.CH0.wav')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model.save('weights/%s.hdf5'%model_name, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-9b575083a062>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;31m#model = load_model(\"weights/model.hdf5\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[1;32mprint\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "#model = load_model(\"weights/model.hdf5\")\n",
    "print x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('M03_051C0102_BTH.CH0.wav', 'M03_051C0102_BUS.CH0.wav')\n"
     ]
    }
   ],
   "source": [
    "print data_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before (26L, 4400L) (25L, 4400L)\n",
      "After (26L, 4400L) (26L, 4400L)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((26L, 1L, 8800L), (26L, 1L, 8800L))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print np.shape(X)\n",
    "# print np.shape(x_data)\n",
    "\n",
    "# op = np.vstack((X, x_data))\n",
    "# print np.shape(op)\n",
    "\n",
    "y,x = data_train[100]\n",
    "#model = load_model(\"weights/model_1.hdf5\")\n",
    "x_block = read_file_as_blocks(x, \"noisy\")\n",
    "y_block = read_file_as_blocks(y, \"clean\")\n",
    "\n",
    "print \"Before\", np.shape(x_block), np.shape(y_block)\n",
    "y_block, x_block = making_same_length(y_block, x_block)\n",
    "print \"After\", np.shape(x_block), np.shape(y_block)\n",
    "\n",
    "x_data = convert_block_to_data(x_block)\n",
    "y_data = convert_block_to_data(y_block)\n",
    "\n",
    "X = x_data\n",
    "Y = y_data\n",
    "\n",
    "np.shape(y_data), np.shape(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(251L, 1L, 8800L) (251L, 1L, 8800L)\n",
      "(500L, 1L, 8800L) (500L, 1L, 8800L)\n",
      "(769L, 1L, 8800L) (769L, 1L, 8800L)\n",
      "(1056L, 1L, 8800L) (1056L, 1L, 8800L)\n",
      "(1303L, 1L, 8800L) (1303L, 1L, 8800L)\n",
      "(1546L, 1L, 8800L) (1546L, 1L, 8800L)\n",
      "(1773L, 1L, 8800L) (1773L, 1L, 8800L)\n",
      "(2003L, 1L, 8800L) (2003L, 1L, 8800L)\n",
      "(2219L, 1L, 8800L) (2219L, 1L, 8800L)\n",
      "(2461L, 1L, 8800L) (2461L, 1L, 8800L)\n",
      "(2687L, 1L, 8800L) (2687L, 1L, 8800L)\n",
      "(2908L, 1L, 8800L) (2908L, 1L, 8800L)\n",
      "(3174L, 1L, 8800L) (3174L, 1L, 8800L)\n",
      "(3417L, 1L, 8800L) (3417L, 1L, 8800L)\n",
      "(3629L, 1L, 8800L) (3629L, 1L, 8800L)\n",
      "(3844L, 1L, 8800L) (3844L, 1L, 8800L)\n",
      "(4012L, 1L, 8800L) (4012L, 1L, 8800L)\n",
      "(4241L, 1L, 8800L) (4241L, 1L, 8800L)\n",
      "(4461L, 1L, 8800L) (4461L, 1L, 8800L)\n",
      "(4700L, 1L, 8800L) (4700L, 1L, 8800L)\n",
      "(4954L, 1L, 8800L) (4954L, 1L, 8800L)\n",
      "(5230L, 1L, 8800L) (5230L, 1L, 8800L)\n",
      "(5469L, 1L, 8800L) (5469L, 1L, 8800L)\n",
      "(5695L, 1L, 8800L) (5695L, 1L, 8800L)\n",
      "(5936L, 1L, 8800L) (5936L, 1L, 8800L)\n",
      "(6154L, 1L, 8800L) (6154L, 1L, 8800L)\n",
      "(6366L, 1L, 8800L) (6366L, 1L, 8800L)\n",
      "(6623L, 1L, 8800L) (6623L, 1L, 8800L)\n",
      "(6866L, 1L, 8800L) (6866L, 1L, 8800L)\n",
      "(7083L, 1L, 8800L) (7083L, 1L, 8800L)\n",
      "(7314L, 1L, 8800L) (7314L, 1L, 8800L)\n",
      "(7581L, 1L, 8800L) (7581L, 1L, 8800L)\n",
      "(7840L, 1L, 8800L) (7840L, 1L, 8800L)\n",
      "(8125L, 1L, 8800L) (8125L, 1L, 8800L)\n",
      "(8331L, 1L, 8800L) (8331L, 1L, 8800L)\n",
      "(8578L, 1L, 8800L) (8578L, 1L, 8800L)\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, len(data_train)):\n",
    "    \n",
    "    y,x = data_train[i]\n",
    "    #print x, y\n",
    "    #model = load_model(\"weights/model_1.hdf5\")\n",
    "    x_block = read_file_as_blocks(x, \"noisy\")\n",
    "    y_block = read_file_as_blocks(y, \"clean\")    \n",
    "    \n",
    "    #print \"Before\", np.shape(x_block), np.shape(y_block)\n",
    "    \n",
    "    y_block, x_block = making_same_length(y_block, x_block)\n",
    "    #print \"After\", np.shape(x_block), np.shape(y_block)\n",
    "    \n",
    "    x_data = convert_block_to_data(x_block)\n",
    "    y_data = convert_block_to_data(y_block)\n",
    "    X = np.vstack((X, x_data))\n",
    "    Y = np.vstack((Y, y_data))\n",
    "    \n",
    "    if(i % 10 == 0):\n",
    "        print np.shape(X), np.shape(Y)\n",
    "\n",
    "#predict_and_dump_output(model, x_data, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14939L, 1L, 8800L), (14939L, 1L, 8800L))"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X), np.shape(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_model()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
